{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Dataset Exploration\n",
    "\n",
    "   This Jupyter notebook is designed to explore the Yelp Dataset. It involves loading several JSON datasets into pandas DataFrames, preprocessing, merging, and exporting them for further analysis. Our goal is to understand the characteristics of businesses, users, reviews, and photos within a specific geographical location and domain (restaurants).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets\n",
    "\n",
    "The first step in our exploration is to load various datasets provided by Yelp. These datasets include information on businesses, users, reviews, and photos. We use the `pd.read_json` function to load each dataset in chunks for efficient memory management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the path to your JSON file\n",
    "file_path = \"./dataset/jsons/yelp_academic_dataset_business.json\"\n",
    "\n",
    "# Directly concatenate the chunks read from the JSON file into a single DataFrame\n",
    "business = pd.concat(\n",
    "    pd.read_json(file_path, lines=True, chunksize=10000),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# 'business' DataFrame now contains all the data from the JSON file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the path to your JSON file\n",
    "file_path = \"./dataset/jsons/yelp_academic_dataset_user.json\"\n",
    "\n",
    "# Directly concatenate the chunks read from the JSON file into a single DataFrame\n",
    "user = pd.concat(\n",
    "    pd.read_json(file_path, lines=True, chunksize=10000),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# The 'user' DataFrame now contains all the data from the JSON file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the path to your JSON file\n",
    "file_path = \"./dataset/jsons/yelp_academic_dataset_review.json\"\n",
    "\n",
    "# Read the JSON file in chunks and concatenate directly without intermediate list comprehension\n",
    "review = pd.concat(\n",
    "    pd.read_json(file_path, lines=True,\n",
    "                 dtype={'review_id': str, 'user_id': str,\n",
    "                        'business_id': str, 'stars': 'int8',\n",
    "                        'date': str, 'text': str, 'useful': 'int8',\n",
    "                        'funny': 'int8', 'cool': 'int8'},\n",
    "                 chunksize=10000),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Now 'review' contains the entire dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the path to your JSON file\n",
    "file_path = \"./dataset/jsons/photos.json\"\n",
    "\n",
    "# Directly concatenate the chunks read from the JSON file into a single DataFrame\n",
    "photo = pd.concat(\n",
    "    pd.read_json(file_path, lines=True, chunksize=10000),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# The 'photo' DataFrame now contains all the data from the JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "After loading the data, we focus on preprocessing. This includes filtering datasets based on specific criteria (like selecting only Nevada-based businesses), merging datasets, and calculating new metrics (such as an adjusted score for businesses based on their reviews).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'business_id' and take the first 'photo_id' from each group\n",
    "first_photo = photo.groupby('business_id', as_index=False).first()[['business_id', 'photo_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_states = ['NV']\n",
    "business = business[business.state.isin(list_of_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def filter_restaurant_businesses(df):\n",
    "    restaurant_set = set(['restaurants', 'fast food', 'sandwiches', 'caterers', 'deserts', 'burgers'])\n",
    "    \n",
    "    # Function to determine if a business is a restaurant\n",
    "    def is_restaurant(categories):\n",
    "        if pd.isna(categories):\n",
    "            return False\n",
    "        categories_set = set(map(str.strip, map(str.lower, categories.split(','))))\n",
    "        if categories_set.intersection(restaurant_set):\n",
    "            return True\n",
    "        return False  # Assuming businesses not explicitly identified as restaurants are not restaurants\n",
    "    \n",
    "    mask = df['categories'].apply(is_restaurant)\n",
    "    \n",
    "    return df[mask]\n",
    "\n",
    "business = filter_restaurant_businesses(business)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1705 entries, 0 to 1704\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   business_id     1705 non-null   object \n",
      " 1   name            1705 non-null   object \n",
      " 2   address         1705 non-null   object \n",
      " 3   city            1705 non-null   object \n",
      " 4   state           1705 non-null   object \n",
      " 5   postal_code     1705 non-null   object \n",
      " 6   latitude        1705 non-null   float64\n",
      " 7   longitude       1705 non-null   float64\n",
      " 8   stars           1705 non-null   float64\n",
      " 9   review_count    1705 non-null   int64  \n",
      " 10  is_open         1705 non-null   int64  \n",
      " 11  attributes      1687 non-null   object \n",
      " 12  categories      1705 non-null   object \n",
      " 13  hours           1450 non-null   object \n",
      " 14  photo_id        1705 non-null   object \n",
      " 15  adjusted_score  1705 non-null   float64\n",
      "dtypes: float64(4), int64(2), object(10)\n",
      "memory usage: 213.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'business' is your DataFrame and already defined.\n",
    "# Perform the merge operation and assign the result back to the original DataFrame variable\n",
    "business = pd.merge(business, first_photo, on=\"business_id\", how=\"left\")\n",
    "\n",
    "# Fill NaN values in the 'photo_id' column with 'no-image'\n",
    "business['photo_id'] = business['photo_id'].fillna('no-image')\n",
    "\n",
    "\n",
    "# Calculate the global mean rating across all businesses\n",
    "global_mean = (business['stars'] * business['review_count']).sum() / business['review_count'].sum()\n",
    "# Determine the median review count (50th percentile) dynamically\n",
    "k = business['review_count'].quantile(0.5)\n",
    "# Calculate the adjusted score for each business\n",
    "business['adjusted_score'] = ((business['review_count'] * business['stars']) + (k * global_mean)) / (business['review_count'] + k)\n",
    "# Sorting the 'business' DataFrame by 'adjusted_score' in descending order, in place\n",
    "business.sort_values(by='adjusted_score', ascending=False, inplace=True)\n",
    "# reset index\n",
    "business.reset_index(drop=True, inplace=True)\n",
    "print(business.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1987843 entries, 0 to 1987842\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   user_id             object \n",
      " 1   name                object \n",
      " 2   review_count        int64  \n",
      " 3   yelping_since       object \n",
      " 4   useful              int64  \n",
      " 5   funny               int64  \n",
      " 6   cool                int64  \n",
      " 7   elite               object \n",
      " 8   friends             object \n",
      " 9   fans                int64  \n",
      " 10  average_stars       float64\n",
      " 11  compliment_hot      int64  \n",
      " 12  compliment_more     int64  \n",
      " 13  compliment_profile  int64  \n",
      " 14  compliment_cute     int64  \n",
      " 15  compliment_list     int64  \n",
      " 16  compliment_note     int64  \n",
      " 17  compliment_plain    int64  \n",
      " 18  compliment_cool     int64  \n",
      " 19  compliment_funny    int64  \n",
      " 20  compliment_writer   int64  \n",
      " 21  compliment_photos   int64  \n",
      "dtypes: float64(1), int64(16), object(5)\n",
      "memory usage: 333.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user = user[(user['review_count'] > 0) & (user['average_stars'] != 0)].reset_index(drop=True)\n",
    "print(user.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244323 entries, 0 to 244322\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   review_id    244323 non-null  object\n",
      " 1   user_id      244323 non-null  object\n",
      " 2   business_id  244323 non-null  object\n",
      " 3   stars        244323 non-null  int8  \n",
      " 4   useful       244323 non-null  int8  \n",
      " 5   funny        244323 non-null  int8  \n",
      " 6   cool         244323 non-null  int8  \n",
      " 7   text         244323 non-null  object\n",
      " 8   date         244323 non-null  object\n",
      "dtypes: int8(4), object(5)\n",
      "memory usage: 10.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_user_ids = set(user.user_id.unique())\n",
    "unique_business_ids = set(business.business_id.unique())\n",
    "\n",
    "review = review[(review.user_id.isin(unique_user_ids)) & \n",
    "                (review.business_id.isin(unique_business_ids)) & \n",
    "                (review.stars != 0)]\n",
    "\n",
    "review.reset_index(drop=True, inplace=True)\n",
    "print(review.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6901 entries, 0 to 6900\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   photo_id     6901 non-null   object\n",
      " 1   business_id  6901 non-null   object\n",
      " 2   caption      6901 non-null   object\n",
      " 3   label        6901 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 215.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "photo = photo[photo.business_id.isin(unique_business_ids)]\n",
    "photo.reset_index(drop=True, inplace=True)\n",
    "print(photo.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data\n",
    "\n",
    "With the data now preprocessed, the final step involves exporting the modified DataFrames to both CSV and pickle formats for easy access in future analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "business.to_csv(path_or_buf='business.csv',index=False)\n",
    "user.to_csv(path_or_buf='user.csv',index=False)\n",
    "review.to_csv(path_or_buf='review.csv',index=False)\n",
    "photo.to_csv(path_or_buf='photo.csv',index=False)\n",
    "\n",
    "business.to_pickle('business.pkl')\n",
    "user.to_pickle('user.pkl')\n",
    "review.to_pickle('review.pkl')\n",
    "photo.to_pickle('photo.pkl')\n",
    "\n",
    "review[['user_id', 'business_id', 'stars', 'date']].to_pickle('review_cache.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
